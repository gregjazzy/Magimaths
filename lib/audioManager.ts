// ï¿½ï¿½ GESTIONNAIRE AUDIO SIMPLIFIÃ‰ AVEC CONFIGURATION FIXE
// Utilise une configuration vocale prÃ©-optimisÃ©e au lieu d'analyser Ã  chaque fois

import { ACTIVE_VOICE_CONFIG, getOptimizedVoice } from './voiceConfig';

interface AudioManagerState {
  currentAudio: HTMLAudioElement | null;
  isPlaying: boolean;
  shouldStop: boolean;
  userHasInteracted: boolean;
  configuredVoice: SpeechSynthesisVoice | null;
}

// Ã‰tat global du gestionnaire audio
const audioState: AudioManagerState = {
  currentAudio: null,
  isPlaying: false,
  shouldStop: false,
  userHasInteracted: false,
  configuredVoice: null
};

// ğŸ¯ INITIALISATION SIMPLE DE LA VOIX CONFIGURÃ‰E
const initializeConfiguredVoice = (): void => {
  // VÃ©rification cÃ´tÃ© client uniquement
  if (typeof window === 'undefined' || !('speechSynthesis' in window)) {
    return;
  }
  
  // Attendre que les voix soient chargÃ©es
  if (speechSynthesis.getVoices().length === 0) {
    speechSynthesis.addEventListener('voiceschanged', () => {
      audioState.configuredVoice = getOptimizedVoice(ACTIVE_VOICE_CONFIG);
      if (audioState.configuredVoice) {
        console.log(`ğŸµ VOIX CONFIGURÃ‰E PRÃŠTE: ${audioState.configuredVoice.name}`);
      }
    });
  } else {
    audioState.configuredVoice = getOptimizedVoice(ACTIVE_VOICE_CONFIG);
  }
};

// Auto-initialisation
initializeConfiguredVoice();

// ğŸµ FONCTION PRINCIPALE HYBRIDE : Audio Premium OU Web Speech API ConfigurÃ©
export const playAudio = (section: string, chapter: string, audioKey: string, fallbackText?: string, rate: number = 1.1): Promise<void> => {
  return new Promise(async (resolve) => {
    // ğŸ›‘ ArrÃªter tout audio en cours
    stopAllAudio();
    
    // ğŸ”’ VÃ©rifier le signal d'arrÃªt
    if (audioState.shouldStop) {
      console.log("ğŸ›‘ ARRÃŠT : Signal d'arrÃªt dÃ©tectÃ©");
      resolve();
      return;
    }
    
    // ğŸ“ Construire le chemin du fichier audio
    const audioPath = `/audio/${section}/${chapter}/${audioKey}.mp3`;
    
    // ğŸ¯ STRATÃ‰GIE 1 : Essayer le fichier audio prÃ©-gÃ©nÃ©rÃ©
    try {
      const audioExists = await checkAudioExists(audioPath);
      
      if (audioExists) {
        console.log(`ğŸµ AUDIO PREMIUM : ${audioPath}`);
        return playPreGeneratedAudio(audioPath, resolve);
      }
    } catch (error) {
      console.log(`ğŸ“ Fichier audio non trouvÃ© : ${audioPath}`);
    }
    
    // ğŸ¯ STRATÃ‰GIE 2 : Fallback sur Web Speech API avec configuration fixe
    if (fallbackText) {
      console.log(`ğŸ”„ FALLBACK WEB SPEECH CONFIGURÃ‰ : ${fallbackText.substring(0, 30)}...`);
      return playConfiguredWebSpeechAudio(fallbackText, rate, resolve);
    }
    
    console.log("âŒ Aucune source audio disponible");
    resolve();
  });
};

// ğŸ” VÃ‰RIFIER L'EXISTENCE D'UN FICHIER AUDIO
const checkAudioExists = (audioPath: string): Promise<boolean> => {
  return new Promise((resolve) => {
    const audio = new Audio();
    audio.oncanplaythrough = () => resolve(true);
    audio.onerror = () => resolve(false);
    audio.src = audioPath;
    // Timeout pour Ã©viter d'attendre indÃ©finiment
    setTimeout(() => resolve(false), 1000);
  });
};

// ğŸµ LECTURE FICHIER AUDIO PRÃ‰-GÃ‰NÃ‰RÃ‰
const playPreGeneratedAudio = (audioPath: string, resolve: () => void): void => {
  const audio = new Audio(audioPath);
  audio.volume = ACTIVE_VOICE_CONFIG.volume;
  audio.playbackRate = 1.0; // Vitesse dÃ©jÃ  optimisÃ©e dans la gÃ©nÃ©ration
  
  // ğŸ“ Mettre Ã  jour l'Ã©tat
  audioState.currentAudio = audio;
  audioState.isPlaying = true;
  
  // ğŸ¯ Event Listeners
  audio.onended = () => {
    console.log(`âœ… AUDIO PREMIUM TERMINÃ‰ : ${audioPath}`);
    audioState.isPlaying = false;
    audioState.currentAudio = null;
    resolve();
  };
  
  audio.onerror = (error) => {
    console.error(`âŒ ERREUR AUDIO PREMIUM : ${audioPath}`, error);
    audioState.isPlaying = false;
    audioState.currentAudio = null;
    resolve();
  };
  
  // ğŸš€ DÃ©marrer la lecture
  audio.play().catch((error) => {
    console.error(`âŒ ERREUR LECTURE PREMIUM : ${audioPath}`, error);
    audioState.isPlaying = false;
    audioState.currentAudio = null;
    resolve();
  });
};

// ğŸ”„ LECTURE WEB SPEECH API AVEC CONFIGURATION FIXE (FALLBACK)
const playConfiguredWebSpeechAudio = (text: string, customRate: number, resolve: () => void): void => {
  // ğŸ”’ VÃ©rification cÃ´tÃ© client uniquement
  if (typeof window === 'undefined' || !('speechSynthesis' in window)) {
    console.log("ğŸš« BLOQUÃ‰ : speechSynthesis non disponible");
    resolve();
    return;
  }
  
  // ğŸ”’ Protection : EmpÃªcher les vocaux sans interaction utilisateur
  if (!audioState.userHasInteracted) {
    console.log("ğŸš« BLOQUÃ‰ : Tentative de vocal sans interaction");
    resolve();
    return;
  }
  
  // ğŸ”¥ ArrÃªt systÃ©matique des vocaux prÃ©cÃ©dents
  speechSynthesis.cancel();
  setTimeout(() => speechSynthesis.cancel(), 10);
  
  const utterance = new SpeechSynthesisUtterance(text);
  
  // ğŸ¯ UTILISER LA VOIX CONFIGURÃ‰E
  if (audioState.configuredVoice) {
    utterance.voice = audioState.configuredVoice;
    console.log(`ğŸµ Utilisation voix configurÃ©e: ${audioState.configuredVoice.name}`);
  } else {
    console.log("âš ï¸ Voix par dÃ©faut utilisÃ©e (configuration en cours...)");
  }
  
  // ğŸ›ï¸ PARAMÃˆTRES FIXES OPTIMISÃ‰S
  utterance.lang = 'fr-FR';
  utterance.rate = customRate * (ACTIVE_VOICE_CONFIG.rate / 1.1); // Ajustement proportionnel
  utterance.pitch = ACTIVE_VOICE_CONFIG.pitch;
  utterance.volume = ACTIVE_VOICE_CONFIG.volume;
  
  utterance.onend = () => {
    console.log("âœ… WEB SPEECH CONFIGURÃ‰ TERMINÃ‰ :", text.substring(0, 30) + "...");
    audioState.isPlaying = false;
    resolve();
  };
  
  utterance.onerror = () => {
    console.log("âŒ ERREUR WEB SPEECH CONFIGURÃ‰ :", text.substring(0, 30) + "...");
    audioState.isPlaying = false;
    resolve();
  };
  
  console.log("ğŸ”„ DÃ‰MARRAGE WEB SPEECH CONFIGURÃ‰ :", text.substring(0, 30) + "...");
  audioState.isPlaying = true;
  speechSynthesis.speak(utterance);
};

// ğŸ›‘ FONCTION D'ARRÃŠT ULTRA-AGRESSIVE HYBRIDE
export const stopAllAudio = (): void => {
  console.log("ğŸ›‘ ARRÃŠT ULTRA-AGRESSIF de tous les audios");
  
  // ğŸµ ArrÃªter l'audio HTML en cours
  if (audioState.currentAudio) {
    audioState.currentAudio.pause();
    audioState.currentAudio.currentTime = 0;
    audioState.currentAudio = null;
  }
  
  // ğŸ”„ ArrÃªter Web Speech API (cÃ´tÃ© client uniquement)
  if (typeof window !== 'undefined' && 'speechSynthesis' in window) {
    speechSynthesis.cancel();
    setTimeout(() => speechSynthesis.cancel(), 10);
    setTimeout(() => speechSynthesis.cancel(), 50);
    setTimeout(() => speechSynthesis.cancel(), 100);
  }
  
  // ğŸ”„ RÃ©initialiser l'Ã©tat
  audioState.isPlaying = false;
  audioState.shouldStop = true;
  
  // ğŸ• RÃ©initialiser le signal d'arrÃªt aprÃ¨s un dÃ©lai
  setTimeout(() => {
    audioState.shouldStop = false;
  }, 500);
};

// ğŸ‘† MARQUER L'INTERACTION UTILISATEUR
export const markUserInteraction = (): void => {
  audioState.userHasInteracted = true;
  console.log("ğŸ‘† Interaction utilisateur dÃ©tectÃ©e");
  
  // Forcer la configuration de la voix si pas encore fait
  if (!audioState.configuredVoice) {
    setTimeout(() => {
      audioState.configuredVoice = getOptimizedVoice(ACTIVE_VOICE_CONFIG);
    }, 100);
  }
};

// ğŸ”§ FONCTIONS DE DIAGNOSTIC SIMPLIFIÃ‰ES
export const showCurrentConfig = (): void => {
  console.log('ğŸµ CONFIGURATION VOCALE ACTIVE');
  console.log('='.repeat(40));
  console.log('ğŸ“Š SystÃ¨me dÃ©tectÃ©:', navigator.userAgent.includes('Mac') ? 'macOS' : 'Autre');
  console.log('ğŸ¤ Voix prÃ©fÃ©rÃ©e:', ACTIVE_VOICE_CONFIG.preferredVoiceName || 'Auto');
  console.log('ğŸ›ï¸ ParamÃ¨tres:');
  console.log(`   Rate: ${ACTIVE_VOICE_CONFIG.rate}`);
  console.log(`   Pitch: ${ACTIVE_VOICE_CONFIG.pitch}`);
  console.log(`   Volume: ${ACTIVE_VOICE_CONFIG.volume}`);
  
  if (audioState.configuredVoice) {
    console.log('âœ… Voix active:', audioState.configuredVoice.name);
  } else {
    console.log('âš ï¸ Voix en cours de configuration...');
  }
};

// ğŸ­ FONCTIONS D'ALIAS POUR COMPATIBILITÃ‰
export const playVocal = (section: string, chapter: string, audioKey: string, fallbackText?: string, rate: number = 1.1): Promise<void> => {
  return playAudio(section, chapter, audioKey, fallbackText, rate);
};

export const stopAllVocals = stopAllAudio;

// ğŸ“Š FONCTION UTILITAIRE : Ã‰tat du gestionnaire
export const getAudioState = (): AudioManagerState => {
  return { ...audioState };
};

// ğŸ¯ FONCTIONS SPÃ‰CIALISÃ‰ES PAR SECTION

// ğŸ”¢ CP-NOMBRES-JUSQU-20
export const playCP20Audio = (chapter: string, audioKey: string, fallbackText?: string): Promise<void> => {
  return playAudio('cp-nombres-jusqu-20', chapter, audioKey, fallbackText);
};

// â• CP-ADDITIONS-SIMPLES
export const playCPAdditionsAudio = (chapter: string, audioKey: string, fallbackText?: string): Promise<void> => {
  return playAudio('cp-additions-simples', chapter, audioKey, fallbackText);
};

// â– CP-SOUSTRACTIONS-SIMPLES
export const playCPSoustractionsAudio = (chapter: string, audioKey: string, fallbackText?: string): Promise<void> => {
  return playAudio('cp-soustractions-simples', chapter, audioKey, fallbackText);
};

// ğŸµ MAPPING DES AUDIOS DISPONIBLES (pour validation)
export const AVAILABLE_AUDIOS = {
  'cp-nombres-jusqu-20': {
    'reconnaissance': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro', 'exercise-instruction'],
    'comptage': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro', 'exercise-instruction'],
    'ecriture': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro', 'exercise-instruction'],
    'dizaines-unites': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro'],
    'doubles-moities': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro'],
    'ordonner-comparer': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro'],
    'decompositions': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro'],
    'complements-10': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro']
  },
  'cp-additions-simples': {
    'sens-addition': ['course-intro', 'course-explanation', 'course-practice', 'course-final', 'exercise-intro'],
    'additions-jusqu-20': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro'],
    'problemes': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro']
  },
  'cp-soustractions-simples': {
    'sens-soustraction': ['course-intro', 'course-explanation', 'course-practice', 'course-final', 'exercise-intro'],
    'soustractions-20': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro'],
    'techniques': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro'],
    'problemes': ['course-intro', 'course-explanation', 'course-practice', 'exercise-intro']
  }
} as const;

// ğŸ¯ FONCTION DE VALIDATION
export const isAudioAvailable = (section: string, chapter: string, audioKey: string): boolean => {
  const sectionAudios = AVAILABLE_AUDIOS[section as keyof typeof AVAILABLE_AUDIOS];
  if (!sectionAudios) return false;
  
  const chapterAudios = sectionAudios[chapter as keyof typeof sectionAudios] as readonly string[] | undefined;
  if (!chapterAudios) return false;
  
  return (chapterAudios as readonly string[]).includes(audioKey);
};

export default {
  playAudio,
  stopAllAudio,
  playVocal,
  stopAllVocals,
  getAudioState,
  markUserInteraction,
  showCurrentConfig,
  playCP20Audio,
  playCPAdditionsAudio,
  playCPSoustractionsAudio,
  isAudioAvailable
}; 